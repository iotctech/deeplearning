\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[12pt,a4paper,UTF8,twoside]{book}

\usepackage{lmodern}
\usepackage{setspace}
\setstretch{1.25}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}

    \setmainfont[]{Times New Roman}
    \setsansfont[]{Arial}
    \setmonofont[Mapping=tex-ansi]{Inconsolata}
\fi

% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage[]{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{hyperref}
\hypersetup{
            pdftitle={深度学习文档集},
            pdfauthor={贝塔},
            pdfproducer={Pandoc, R Markdown, TinyTeX, knitr, bookdown, Stan},
            pdfborder={0 0 0},
            breaklinks=true}
\urlstyle{same}  % don't use monospace font for urls
\usepackage[margin=1.18in]{geometry}
\usepackage{longtable,booktabs}
% Fix footnotes in tables (requires footnote package)
\IfFileExists{footnote.sty}{\usepackage{footnote}\makesavenoteenv{longtable}}{}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
% Redefines (sub)paragraphs to behave more like sections
\ifx\paragraph\undefined\else
\let\oldparagraph\paragraph
\renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
\let\oldsubparagraph\subparagraph
\renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

% set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother

\usepackage[UTF8, heading, fontset=none]{ctex}
\usepackage{amssymb,amsmath,amsfonts,mathrsfs}
% \setCJKmainfont[ItalicFont={KaiTi_GB2312}, BoldFont={SimHei}]{SimSun}
\setCJKmainfont[ItalicFont={CESI_KT_GB2312}, BoldFont={SimHei}]{SimSun}
\setCJKsansfont{SimHei}
% \setCJKmonofont{FangSong_GB2312}
\setCJKmonofont{CESI_FS_GB2312}

\setCJKfamilyfont{heiti}{SimHei}             
\newcommand{\heiti}{\CJKfamily{heiti}}

% \setCJKfamilyfont{kaishu}{KaiTi_GB2312}             
\setCJKfamilyfont{kaishu}{CESI_KT_GB2312}             
\newcommand{\kaishu}{\CJKfamily{kaishu}}

\setCJKfamilyfont{songti}{SimSun}             
\newcommand{\songti}{\CJKfamily{songti}}

% \setCJKfamilyfont{fangsong}{FangSong_GB2312}             
\setCJKfamilyfont{fangsong}{CESI_FS_GB2312}             
\newcommand{\fangsong}{\CJKfamily{fangsong}}

\usepackage{color}
\ctexset{
  chapter/name = {,},
  chapter/number = \arabic{chapter},
  chapter/numberformat = \sf,
  chapter/beforeskip = 12pt,
  chapter/afterskip = 18pt,
  chapter/fixskip = true,
  chapter/format += \sf\zihao{3},
  section/numberformat = \rm,
  section/format += \sf\zihao{4}\raggedright,
  section/beforeskip = 16pt,
  section/afterskip = 16pt,
  section/fixskip = true,
  subsection/numberformat = \rm,
  subsection/format += \sf\zihao{-4}\raggedright,
  subsection/fixskip = true,
  subsection/beforeskip = 16pt,
  subsection/afterskip = 16pt,
  subsubsection/numberformat = \rm,
  subsubsection/format += \sf\zihao{-4}\raggedright,
  contentsname = {目\quad 录},
}

\usepackage[titles]{tocloft}
\renewcommand{\cftdot}{$\ldotp$}
\renewcommand{\cftdotsep}{0}
\renewcommand{\cftchapleader}{\cftdotfill{\cftchapdotsep}}
\renewcommand{\cftchapdotsep}{\cftdotsep}

\usepackage[lotdepth=2,lofdepth=2]{subfig}

\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\renewcommand{\headrule}{\hrule height1pt width\headwidth \vspace{3.0pt}\hrule width\headwidth}
% \fancyhead[EC]{\kaishu \zihao{5}中国矿业大学（北京）硕士学位论文}
\fancyhead[EC]{\kaishu \zihao{5}https://iotctech.github.io/deeplearning}
\fancyhead[OC]{\kaishu \zihao{5}\leftmark}
\fancyfoot[C]{\thepage}

\fancypagestyle{plain}{ \fancyhf{}
% \fancyhead[EC]{\kaishu\zihao{5} 中国矿业大学（北京）硕士学位论文}
\fancyhead[EC]{\kaishu\zihao{5} https://iotctech.github.io/deeplearning}
\fancyhead[OC]{\kaishu\zihao{5} \leftmark}
\fancyfoot[C]{\thepage}}

\usepackage{array}
\usepackage{multirow}
\usepackage[table]{xcolor}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}

\frontmatter

\usepackage[super,square,sort]{natbib}
\bibliographystyle{GBT7714-2005}


\title{深度学习文档集}
\providecommand{\subtitle}[1]{}
\subtitle{Deep Learning Book}
\author{贝塔}
\date{2020-03-22}

\usepackage{amsthm}
\newtheorem{theorem}{定理}[chapter]
\newtheorem{lemma}{引理}[chapter]
\newtheorem{corollary}{推论}[chapter]
\newtheorem{proposition}{命题}[chapter]
\newtheorem{conjecture}{Conjecture}[chapter]
\theoremstyle{definition}
\newtheorem{definition}{定义}[chapter]
\theoremstyle{definition}
\newtheorem{example}{例}[chapter]
\theoremstyle{definition}
\newtheorem{exercise}{练习}[chapter]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\let\BeginKnitrBlock\begin \let\EndKnitrBlock\end
\begin{document}
% \maketitle

%\input{latex/00a-cover.tex}  % 封面

%\input{latex/00b-titlepage.tex}  % 标题

%\input{latex/00c-declaration.tex}  % 声明

%\input{latex/00d-abstract.tex}  % 摘要

{
\setcounter{tocdepth}{2}
\tableofcontents
}

\hypertarget{ux5199ux5728ux524dux9762}{%
\chapter{写在前面}\label{ux5199ux5728ux524dux9762}}

\emph{Life, thin and light-off time and time again}

\emph{Frivolous tireless}

生命，一次又一次轻薄过

轻狂不知疲倦

\hypertarget{prepare}{%
\chapter{基础知识}\label{prepare}}

作为第 \ref{models} 章统计模型和第 \ref{algorithms} 章参数估计的知识准备，本章给出主要的知识点。第 \ref{sec:exp} 节首先介绍指数族的一般形式，包含各成分的定义，特别介绍正态分布、二项分布和泊松分布情形下均值函数、联系函数和方差函数等特征量。第 \ref{sec:lse} 节介绍线性模型下，设计矩阵保持正定时的最小二乘估计和加权最小二乘估计。第 \ref{sec:def-mle} 节介绍极大似然估计的定义，相合性，以及在一定条件下的渐近正态性。第 \ref{sec:stationary-gaussian-process} 节介绍平稳高斯过程的定义，均方连续性和可微性的定义，以及判断可微性的一个充要条件。第 \ref{sec:bayes-prior} 介绍先验、后验分布和 Jeffreys 无信息先验分布。

\hypertarget{sec:exp}{%
\section{指数族}\label{sec:exp}}

一般地，随机变量 \(Y\) 的分布服从指数族，即形如
\begin{equation}
f_{Y}(y;\theta,\phi) = \exp\big\{ \big(y\theta - b(\theta) \big)/a(\phi) + c(y,\phi) \big\}
\label{eq:common-exponential-family}
\end{equation}
\noindent 其中，\(a(\cdot),b(\cdot),c(\cdot)\) 是某些特定的函数。如果 \(\phi\) 已知，这是一个含有典则参数 \(\theta\) 的指数族模型，如果 \(\phi\) 未知，它可能是含有两个参数的指数族。对于正态分布
\begin{equation}
\begin{aligned}
f_{Y}(y;\theta,\phi) & = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{(y - \mu)^2}{2\sigma^2}  \}  \\
 & = \exp\big \{ (y\mu - \mu^2/2)/\sigma^2 - \frac{1}{2}\big(y^2/\sigma^2 + \log(2\pi\sigma^2)\big) \big\}
\end{aligned} \label{eq:normal-distribution}
\end{equation}
\noindent 通过与 \eqref{eq:common-exponential-family} 式对比，可知 \(\theta = \mu\)，\(\phi = \sigma^2\)，并且有
\[
a(\phi) = \phi, \quad b(\theta) = \theta^2/2, \quad c(y,\phi) = - \frac{1}{2}\{ y^2/\sigma^2 + \log(2\pi\sigma^2) \} 
\]
\noindent 记 \(l(\theta,\phi;y) = \log f_{Y}(y;\theta,\phi)\) 为给定样本点 \(y\) 的情况下，关于 \(\theta\) 和 \(\phi\) 的对数似然函数。样本 \(Y\) 的均值和方差具有如下关系 \citep{McCullagh1989}
\begin{equation}
\mathsf{E}\big( \frac{\partial l}{\partial \theta} \big) = 0
\label{eq:mean-log-lik}
\end{equation}
\noindent 和
\begin{equation}
\mathsf{E}\big( \frac{\partial^2 l}{\partial \theta^2} \big) + \mathsf{E}\big(\frac{\partial l}{\partial \theta}\big)^2  = 0
\label{eq:variance-log-lik}
\end{equation}
\noindent 从 \eqref{eq:common-exponential-family} 式知
\[ l(\theta,\phi;y) = {y\theta - b(\theta)}/a(\phi) + c(y,\phi) \]
\noindent 因此，
\begin{equation}
\begin{aligned}
\frac{\partial l}{\partial \theta} & = {y - b'(\theta)}/a(\phi)  \\
\frac{\partial^2 l}{\partial \theta^2}  & = - b''(\theta)/a(\phi)
\end{aligned} \label{eq:partial-log-lik}
\end{equation}
\noindent 从 \eqref{eq:mean-log-lik} 式和 \eqref{eq:partial-log-lik}，可以得出
\[ 
0 = \mathsf{E}\big( \frac{\partial l}{\partial \theta} \big) = \big\{ \mu - b'(\theta) \big\}/a(\phi)
\]
\noindent 所以
\[ \mathsf{E}(Y) = \mu = b'(\theta) \]
\noindent 根据 \eqref{eq:variance-log-lik} 式和 \eqref{eq:partial-log-lik} 式，可得
\[ 0 = - \frac{b''(\theta)}{a(\phi)} + \frac{\mathsf{Var}(Y)}{a^2(\phi)} \]
\noindent 所以
\[ \mathsf{Var}(Y) = b''(\theta)a(\phi) \]
可见，\(Y\) 的方差是两个函数的乘积，一个是 \(b''(\theta)\)， 它仅仅依赖典则参数，叫做方差函数，方差函数可以看作是 \(\mu\) 的函数，记作 \(V(\mu)\)。另一个是 \(a(\phi)\)，它独立于 \(\theta\)，仅仅依赖 \(\phi\)，函数 \(a(\phi)\) 通常形如
\[ a(\phi) = \phi/w \]
\noindent 其中 \(\phi\) 可由 \(\sigma^2\) 表示，故而也叫做发散参数 （dispersion parameter），是一个与样本观察值相关的常数，\(w\) 是已知的权重，随样本观察值变化。对正态分布模型而言，\(w\) 的分量是 \(m\) 个相互独立的样本观察值的均值，有 \(a(\phi) = \sigma^2/m\)，所以，\(w = m\)。

根据 \eqref{eq:common-exponential-family}式，正态、泊松和二项分布的特征见表 \ref{tab:common-characteristics}，符号约定同 McCullagh 和 Nelder （1989年） 所著的《广义线性模型》。

\begin{longtable}[]{@{}lccc@{}}
\caption{\label{tab:common-characteristics} 指数族内常见的一元分布的共同特征及符号表示}\tabularnewline
\toprule
\begin{minipage}[b]{0.21\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
正态分布\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
泊松分布\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
二项分布\strut
\end{minipage}\tabularnewline
\midrule
\endfirsthead
\toprule
\begin{minipage}[b]{0.21\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
正态分布\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
泊松分布\strut
\end{minipage} & \begin{minipage}[b]{0.22\columnwidth}\centering
二项分布\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.21\columnwidth}\raggedright
记号\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\mathcal{N}(\mu,\sigma^2)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\mathrm{Poisson}(\mu)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\mathrm{Binomial}(m,p)\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\(y\) 取值范围\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\((-\infty,\infty)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(0(1)\infty\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(0(1)m\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\(\phi\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\phi = \sigma^2\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(1\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(1/m\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\(b(\theta)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\theta^2/2\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\exp(\theta)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\log(1+e^{\theta})\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\(c(y;\theta)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(-\frac{1}{2}\big( \frac{y^2}{\phi} + \log(2\pi\phi) \big)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(-\log(y!)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\log\binom{m}{my}\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
\(\mu(\theta) = \mathsf{E}(Y;\theta)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\theta\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\exp(\theta)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(e^{\theta}/(1+e^{\theta})\)\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
联系函数：\(\theta(\mu)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
identity\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
log\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
logit\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.21\columnwidth}\raggedright
方差函数：\(V(\mu)\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
1\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\mu\)\strut
\end{minipage} & \begin{minipage}[t]{0.22\columnwidth}\centering
\(\mu(1-\mu)\)\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

\hypertarget{sec:lse}{%
\section{最小二乘估计}\label{sec:lse}}

考虑如下线性模型的最小二乘估计
\begin{equation}
\mathsf{E}\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} \qquad \mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{I}_{n} \label{eq:linear-models}
\end{equation}
\noindent 其中， \(\mathbf{Y}\) 为 \(n \times 1\) 维观测向量， \(\mathbf{X}\) 为已知的 \(n \times p (p \leq n)\) 维设计矩阵，\(\boldsymbol{\beta}\) 为 \(p \times 1\) 维未知参数，\(\sigma^2\) 未知，\(\mathbf{I}_{n}\) 为 \(n\) 阶单位阵。
\BeginKnitrBlock{definition}[最小二乘估计]
\protect\hypertarget{def:least-squares-estimate}{}{\label{def:least-squares-estimate} \iffalse (最小二乘估计) \fi{} }在模型 \eqref{eq:linear-models} 中，如果
\begin{equation}
(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}})^{\top}(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}) = \min_{\beta}(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta})^{\top}(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}) \label{eq:least-squares}
\end{equation}
\noindent 则称 \(\hat{\boldsymbol{\beta}}\) 为 \(\boldsymbol{\beta}\) 的最小二乘估计(简称 LSE)\citep{wang2004}。
\EndKnitrBlock{definition}

\BeginKnitrBlock{theorem}[最小二乘估计]
\protect\hypertarget{thm:unbiased}{}{\label{thm:unbiased} \iffalse (最小二乘估计) \fi{} }若模型 \eqref{eq:linear-models} 中的 \(\mathbf{X}\) 是列满秩的矩阵，则 \(\boldsymbol{\beta}\) 的最小二乘估计为
\[
\hat{\boldsymbol{\beta}}_{LS} = ( \mathbf{X}^{\top}\mathbf{X} )^{-1}\mathbf{X}^{\top} \mathbf{Y}, \quad  \mathsf{Var}(\hat{\boldsymbol{\beta}}_{LS}) = \sigma^2 (\mathbf{X}^{\top}\mathbf{X})^{-1}  
\]
\noindent \(\sigma^2\) 的最小二乘估计为
\[
\hat{\sigma^2}_{LS} = (\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}_{LS})^{\top}(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}_{LS})/(n - p)
\]
若将模型 \eqref{eq:linear-models} 的条件 \(\mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{I}_{n}\) 改为 \(\mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{G}\)， \(\mathbf{G}(>0)\) 为已知正定阵，则\(\boldsymbol{\beta}\) 的最小二乘估计为
\[
\tilde{\boldsymbol{\beta}}_{LS} = ( \mathbf{X}^{\top} \mathbf{G}^{-1} \mathbf{X})^{-1} \mathbf{X}^{\top} \mathbf{G}^{-1} \mathbf{Y} 
\]
\noindent 称 \(\tilde{\boldsymbol{\beta}}_{LS}\) 为广义最小二乘估计，特别地，当 \(\mathbf{G} = \mathrm{diag}(\sigma^2_{1},\ldots,\sigma^2_{n})\)，\(\sigma^2_{i},i = 1,\ldots,n\) 已知时，称 \(\tilde{\boldsymbol{\beta}}_{LS}\) 为加权最小二乘估计\citep{wang2004}。
\EndKnitrBlock{theorem}

\hypertarget{sec:def-mle}{%
\section{极大似然估计}\label{sec:def-mle}}

\BeginKnitrBlock{definition}[极大似然估计]
\protect\hypertarget{def:maximum-likelihood-estimate}{}{\label{def:maximum-likelihood-estimate} \iffalse (极大似然估计) \fi{} }设 \(p(\mathbf{x};\boldsymbol{\theta}),\boldsymbol{\theta} \in \boldsymbol{\Theta}\) 是 \((\mathbb{R}^n,\mathscr{P}_{\mathbb{R}^n})\) 上的一族联合密度函数，对给定的 \(\mathbf{x}\)，称
\[ L(\boldsymbol{\theta};\mathbf{x}) = kp(\mathbf{x};\boldsymbol{\theta}) \]
\noindent 为 \(\boldsymbol{\theta}\) 的似然函数，其中 \(k > 0\) 是不依赖于 \(\boldsymbol{\theta}\) 的量，常取 \(k=1\)。进一步，若存在 \((\mathbb{R}^n,\mathscr{P}_{\mathbb{R}^n})\) 到 \((\boldsymbol{\Theta},\mathscr{P}_{\boldsymbol{\Theta}})\) 的统计量 \(\hat{\boldsymbol{\theta}}(\mathbf{x})\) 使
\[ L(\hat{\boldsymbol{\theta}}(\mathbf{x});\mathbf{x}) = \sup_{\boldsymbol{\theta}} L(\boldsymbol{\theta};\mathbf{x}) \]
\noindent 则 \(\hat{\boldsymbol{\theta}}(\mathbf{x})\) 称为 \(\boldsymbol{\theta}\) 的一个极大似然估计（简称 MLE）\citep{mao2006}。
\EndKnitrBlock{definition}

概率密度函数很多可以写成具有指数函数的形式，如指数族，采用似然函数的对数通常更为简便。称
\[ l(\boldsymbol{\theta},\mathbf{x}) = \ln L(\boldsymbol{\theta},\mathbf{x}) \]
\noindent 为 \(\boldsymbol{\theta}\) 的对数似然函数。对数变换是严格单调的，所以 \(l(\boldsymbol{\theta},\mathbf{x})\) 与 \(L(\boldsymbol{\theta},\mathbf{x})\) 的极大值是等价的。当 MLE 存在时，寻找 MLE 的常用方法是求导数。如果 \(\hat{\boldsymbol{\theta}}(\mathbf{x})\) 是 \(\boldsymbol{\Theta}\) 的内点，则 \(\hat{\boldsymbol{\theta}}(\mathbf{x})\) 是下列似然方程组
\begin{equation}
\partial l(\boldsymbol{\theta},\mathbf{x})/ \partial \boldsymbol{\theta}_{i} = 0, \quad i = 1,\ldots, m \label{eq:likelihood-equations}
\end{equation}
\noindent 的解。\(p(\mathbf{x};\boldsymbol{\theta})\) 属于指数族时，似然方程组 \eqref{eq:likelihood-equations} 的解唯一\citep{mao2006}。

\BeginKnitrBlock{theorem}[相合性]
\protect\hypertarget{thm:consistency}{}{\label{thm:consistency} \iffalse (相合性) \fi{} }设 \(x_{1}, \ldots, x_{n}\) 是来自概率密度函数 \(p(\mathbf{x};\boldsymbol{\theta})\) 的一个样本，叙述简单起见，考虑单参数情形，参数空间 \(\boldsymbol{\Theta}\) 是一个开区间，\(l(\boldsymbol{\theta};\mathbf{x}) = \sum_{i=1}^{n}\ln p(x_{i};\boldsymbol{\theta})\)。

若 \(\ln (p;\boldsymbol{\theta})\) 在 \(\boldsymbol{\Theta}\) 上可微，且 \(p(\mathbf{x};\boldsymbol{\theta})\) 是可识别的（即 \(\forall \boldsymbol{\theta}_1 \neq \boldsymbol{\theta}_2, \{\mathbf{x}: p(\mathbf{x};\boldsymbol{\theta}_1) \neq p(\mathbf{x}; \boldsymbol{\theta}_2)\}\) 不是零测集），则似然方程 \eqref{eq:likelihood-equations} 在 \(n \to \infty\) 时，以概率 \(1\) 有解，且此解关于 \(\boldsymbol{\theta}\) 是相合的\citep{mao2006}。
\EndKnitrBlock{theorem}

\BeginKnitrBlock{theorem}[渐近正态性]
\protect\hypertarget{thm:asymptotic-normality}{}{\label{thm:asymptotic-normality} \iffalse (渐近正态性) \fi{} }假设 \(\boldsymbol{\Theta}\) 为开区间，概率密度函数 \(p(\mathbf{x};\boldsymbol{\theta}), \boldsymbol{\theta} \in \boldsymbol{\Theta}\) 满足：

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  在参数真值 \(\boldsymbol{\theta}_{0}\) 的邻域内，\(\partial \ln p/\partial \boldsymbol{\theta}, \partial^2 \ln p/\partial \boldsymbol{\theta}^2, \partial^3 \ln p/\partial \boldsymbol{\theta}^3\) 对所有的 \(\mathbf{x}\) 都存在；
\item
  在参数真值 \(\boldsymbol{\theta}_{0}\) 的邻域内，\(| \partial^3 \ln p/\partial \boldsymbol{\theta}^3 | \leq H(\mathbf{x})\)，且 \(\mathsf{E}H(\mathbf{x}) < \infty\)；
\item
  在参数真值 \(\boldsymbol{\theta}_{0}\) 处，\(\mathsf{E}_{\boldsymbol{\theta}_{0}} \big[ \frac{ p'(\mathbf{x},\boldsymbol{\theta}_{0}) }{ p(\mathbf{x},\boldsymbol{\theta}_{0}) } \big] = 0,\mathsf{E}_{\boldsymbol{\theta}_{0}} \big[ \frac{ p''(\mathbf{x},\boldsymbol{\theta}_{0}) }{ p(\mathbf{x},\boldsymbol{\theta}_{0}) } \big] = 0,I(\boldsymbol{\theta}_{0}) = \mathsf{E}_{\boldsymbol{\theta}_{0}} \big[ \frac{ p'(\mathbf{x},\boldsymbol{\theta}_{0}) }{ p(\mathbf{x},\boldsymbol{\theta}_{0}) } \big]^{2} > 0\)。
\end{enumerate}

\noindent 其中，撇号表示对 \(\boldsymbol{\theta}\) 的微分。记 \(\hat{\boldsymbol{\theta}}_{n}\) 为 \(n \to \infty\) 时，似然方程组的相合解，则\(\sqrt{n}(\hat{\boldsymbol{\theta}}_{n} - \boldsymbol{\theta}_{0}) \longrightarrow \mathcal{N}(\mathbf{0},I^{-1}(\boldsymbol{\theta}))\)\citep{mao2006}。
\EndKnitrBlock{theorem}

\hypertarget{sec:stationary-gaussian-process}{%
\section{平稳高斯过程}\label{sec:stationary-gaussian-process}}

一般地，空间高斯过程 \(\mathcal{S} = \{S(x),x\in\mathbb{R}^2\}\) 必须满足条件：任意给定一组空间位置 \(x_1,x_2,\ldots,x_n, \forall x_{i} \in \mathbb{R}^2\)， 每个位置上对应的随机变量 \(S(x_i), i = 1,2,\ldots,n\) 的联合分布 \(\mathcal{S} = \{S(x_1), S(x_2),\ldots,S(x_n)\}\) 是多元高斯分布，其由均值 \(\mu(x) = \mathsf{E}[S(x)]\) 和协方差 \(G_{ij} = \gamma(x_i,x_j) = \mathsf{Cov}\{S(x_i),S(x_j)\}\) 完全确定，即 \(\mathcal{S} \sim \mathcal{N}(\mu_{S},G)\)。

平稳空间高斯过程需要空间高斯过程满足平稳性条件：其一， \(\mu(x) = \mu, \forall x \in \mathbb{R}^2\)， 其二，自协方差函数 \(\gamma(x_i,x_j) = \gamma(u),u=\|x_{i} - x_{j}\|\)。 可见均值 \(\mu\) 是一个常数， 而自协方差函数 \(\gamma(x_i,x_j)\) 只与空间距离有关。

平稳高斯过程 \(\mathcal{S}\) 的方差是一个常数，即 \(\sigma^2 = \gamma(0)\)， 然后可以定义自相关函数 \(\rho(u) = \gamma(u)/\sigma^2\)， 并且 \(\rho(u)\) 是关于空间距离\(u\)对称的，即 \(\rho(u) = \rho(-u)\)。 因为对 \(\forall u, \mathsf{Corr}\{S(x),S(x-u)\} = \mathsf{Corr}\{S(x-u), S(x)\} = \mathsf{Corr}\{S(x),S(x+u)\}\)， 这里的第二个等式是根据平稳性得来的， 由协方差的定义不难验证。 如果不特别说明， 平稳就指上述协方差意义下的平稳， 因为这种平稳性条件广泛应用于空间数据的统计建模。不失一般性，介绍一维空间下随机过程 \(S(x)\) 的均方连续性和可微性定义。

\BeginKnitrBlock{definition}[连续性和可微性]
\protect\hypertarget{def:continuous-differentiable}{}{\label{def:continuous-differentiable} \iffalse (连续性和可微性) \fi{} }随机过程 \(S(x)\) 满足
\[ \lim_{h \to 0} \mathsf{E}\big[ \{S(x + h) - S(x)\}^{2} \big] = 0 \]
\noindent 则称 \(S(x)\) 是均方连续（mean-square continuous）的。随机过程 \(S(x)\) 满足
\[ \lim_{h \to 0} \mathsf{E} \big[ \{ \frac{S(x+h) - S(x)}{h} - S'(x) \}^2 \big] = 0 \]
\noindent 则称 \(S(x)\) 是均方可微（mean-square differentiable）的，并且 \(S'(x)\) 就是均方意义下的一阶导数。如果 \(S'(x)\) 是均方可微的，则 \(S(x)\) 是二次均方可微的，随机过程 \(S(x)\) 的高阶均方可微性可类似定义\citep{Diggle2007}。Bartlett （1955 年） \citep{Bartlett1955} 得到如下重要结论
\EndKnitrBlock{definition}

\BeginKnitrBlock{theorem}[平稳随机过程的可微性]
\protect\hypertarget{thm:stationary-mean-square-properties}{}{\label{thm:stationary-mean-square-properties} \iffalse (平稳随机过程的可微性) \fi{} }自相关函数为 \(\rho(u)\) 的平稳随机过程是 \(k\) 次均方可微的，当且仅当 \(\rho(u)\) 在 \(u = 0\) 处是 \(2k\) 次可微的。
\EndKnitrBlock{theorem}

\hypertarget{sec:bayes-prior}{%
\section{先验和后验分布}\label{sec:bayes-prior}}

贝叶斯推断中，常涉及模型参数的先验、后验分布，以及一种特殊的无信息先验分布 --- Jeffreys 先验，下面分别给出它们的概念定义\citep{mao2006}。

\BeginKnitrBlock{definition}[先验分布]
\protect\hypertarget{def:prior-distribution}{}{\label{def:prior-distribution} \iffalse (先验分布) \fi{} }参数空间 \(\Theta\) 上的任一概率分布都称作先验分布 （prior distribution）\citep{mao2006}。
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}[后验分布]
\protect\hypertarget{def:posterior-distribution}{}{\label{def:posterior-distribution} \iffalse (后验分布) \fi{} }在获得样本 \(\mathbf{Y}\) 后，模型参数 \(\boldsymbol{\theta}\) 的后验分布 （posterior distribution） 就是在给定样本 \(\mathbf{Y}\) 的条件下 \(\boldsymbol{\theta}\) 的分布\citep{mao2006}。
\EndKnitrBlock{definition}

\BeginKnitrBlock{definition}[Jeffreys 先验分布]
\protect\hypertarget{def:Jeffreys-prior-distribution}{}{\label{def:Jeffreys-prior-distribution} \iffalse (Jeffreys 先验分布) \fi{} }设 \(\mathbf{x} = (x_1,\ldots,x_n)\) 是来自密度函数 \(p(x|\boldsymbol{\theta})\) 的一个样本，其中 \(\boldsymbol{\theta} = (\theta_1,\ldots,\theta_p)\) 是 \(p\) 维参数向量。在对 \(\boldsymbol{\theta}\) 无任何先验信息可用时， Jeffreys （1961年）利用变换群和 Harr 测度导出 \(\boldsymbol{\theta}\) 的无信息先验分布可用 Fisher 信息阵的行列式的平方根表示。这种无信息先验分布常称为 Jeffreys 先验分布。其求取步骤如下：
\EndKnitrBlock{definition}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  写出样本的对数似然函数 \(l(\boldsymbol{\theta}|x) = \sum_{i=1}^{n}\ln p(x_i | \boldsymbol{\theta})\)；
\item
  算出参数 \(\boldsymbol{\theta}\) 的 Fisher 信息阵 \[\mathbf{I}(\boldsymbol{\theta}) = \mathsf{E}_{x|\theta} \big( - \frac{\partial^2 l}{\partial \theta_i \partial \theta_j} \big)_{i,j=1,\ldots,p}\] 在单参数场合， \(\mathbf{I}(\theta) = \mathsf{E}_{x|\theta} \big( - \frac{\partial^2 l}{\partial \theta^2} \big)\)；
\item
  \(\boldsymbol{\theta}\) 的无信息先验密度函数为 \(\pi(\boldsymbol{\theta}) = [\det \mathbf{I}(\boldsymbol{\theta}) ]^{1/2}\)，在单参数场合， \(\pi(\boldsymbol{\theta}) = [\mathbf{I}(\theta) ]^{1/2}\)\citep{mao2006}。
\end{enumerate}

\hypertarget{sec:bayes-estimates}{%
\section{常用贝叶斯估计}\label{sec:bayes-estimates}}

\BeginKnitrBlock{theorem}[平方损失]
\protect\hypertarget{thm:bayes-estimate-square}{}{\label{thm:bayes-estimate-square} \iffalse (平方损失) \fi{} }在给定先验分布 \(\pi(\boldsymbol{\theta})\) 和平方损失 \(L(\boldsymbol{\theta},\boldsymbol{\delta}) = (\boldsymbol{\delta} - \boldsymbol{\theta})^2\) 下，\(\boldsymbol{\theta}\) 的贝叶斯估计 \(\boldsymbol{\delta}^{\pi}(x)\) 为后验分布 \(\pi(\boldsymbol{\theta}|x)\) 的均值，即 \(\boldsymbol{\delta}^{\pi}(x) = \mathsf{E}(\boldsymbol{\theta}|x)\)\citep{mao2006}。
\EndKnitrBlock{theorem}

\BeginKnitrBlock{theorem}[0 - 1 损失]
\protect\hypertarget{thm:bayes-estimate-01}{}{\label{thm:bayes-estimate-01} \iffalse (0 - 1 损失) \fi{} }在给定先验分布 \(\pi(\boldsymbol{\theta})\) 和 \(0\) - \(1\) 损失函数

\begin{equation*}
L(\boldsymbol{\theta},\boldsymbol{\delta}) = 
\begin{cases}
1, & | \boldsymbol{\delta} - \boldsymbol{\theta}| \leq \epsilon \\
0, & | \boldsymbol{\delta} - \boldsymbol{\theta}| > \epsilon
\end{cases}
\end{equation*}

当 \(\epsilon\) 较小时，\(\boldsymbol{\theta}\) 的贝叶斯估计\(\boldsymbol{\delta}^{\pi}(x)\)为后验分布 \(\pi(\boldsymbol{\theta}|x)\) 的众数\citep{mao2006}。
\EndKnitrBlock{theorem}

\BeginKnitrBlock{theorem}[绝对值损失]
\protect\hypertarget{thm:bayes-estimate-abs}{}{\label{thm:bayes-estimate-abs} \iffalse (绝对值损失) \fi{} }在给定先验分布 \(\pi(\boldsymbol{\theta})\) 和绝对损失函数 \(L(\boldsymbol{\theta},\boldsymbol{\delta}) = |\boldsymbol{\delta} - \boldsymbol{\theta}|\) 下，\(\boldsymbol{\theta}\) 的贝叶斯估计 \(\boldsymbol{\delta}^{\pi}(x)\) 为后验分布 \(\pi(\boldsymbol{\theta}|x)\) 的中位数\citep{mao2006}。
\EndKnitrBlock{theorem}

评价贝叶斯估计 \(\boldsymbol{\delta}^{\pi}(x)\) 的精度常用后验均方误差
\[\mathsf{MSE}(\boldsymbol{\delta}^{\pi}|x) = \mathsf{E}_{\boldsymbol{\theta}|x}(\boldsymbol{\delta}^{\pi} - \boldsymbol{\theta})^2\]
表示，或用其平方根\([\mathsf{MSE}(\boldsymbol{\delta}^{\pi}|x)]^{1/2}\) （称为标准误）表示。容易算得
\[\mathsf{MSE}(\boldsymbol{\delta}^{\pi}|x) = \mathsf{Var}(\boldsymbol{\delta}^{\pi}|x) + [\boldsymbol{\delta}^{\pi}(x) - \mathsf{E}(\boldsymbol{\theta}|x)]^2\]
可见，当贝叶斯估计\(\boldsymbol{\delta}^{\pi}(x)\)为后验均值时，贝叶斯估计的精度就用\(\boldsymbol{\delta}^{\pi}\)的后验方差\(\mathsf{Var}(\boldsymbol{\delta}^{\pi}|x)\) 表示，或用后验标准差 \([\mathsf{Var}(\boldsymbol{\delta}^{\pi}|x)]^{1/2}\) 表示 \citep{mao2006}。

\hypertarget{sec:foundations}{%
\section{本章小结}\label{sec:foundations}}

本章第\ref{sec:exp}节介绍了指数族的一般形式，指出基于样本点的对数似然函数和样本均值、样本方差的关系，以表格的形式列出了正态、泊松和二项分布的各个特征，为第\ref{models}章统计模型和第\ref{algorithms}章参数估计作铺垫。接着，第\ref{sec:lse}节和第\ref{sec:def-mle}节分别介绍了最小二乘估计和极大似然估计的定义、性质，给出了线性模型的最小二乘估计，极大似然估计的相合性和渐进正态性。第\ref{sec:stationary-gaussian-process}节介绍了平稳高斯过程，给出了其均方连续性、可微性定义以及一个均方可微的判断定理，平稳高斯过程作为空间随机效应的实现，多次出现在后续章节中。第\ref{sec:bayes-prior}节至第\ref{sec:bayes-estimates}节分别是与贝叶斯相关的概念定义。

\hypertarget{literature}{%
\chapter{Literature}\label{literature}}

Here is a review of existing methods.

\hypertarget{methods}{%
\chapter{Methods}\label{methods}}

We describe our methods in this chapter.

\hypertarget{applications}{%
\chapter{Applications}\label{applications}}

Some \emph{significant} applications are demonstrated in this chapter.

\hypertarget{example-one}{%
\section{Example one}\label{example-one}}

\hypertarget{example-two}{%
\section{Example two}\label{example-two}}

\hypertarget{final-words}{%
\chapter{Final Words}\label{final-words}}

We have finished a nice book.


\backmatter
% \printindex

\end{document}
