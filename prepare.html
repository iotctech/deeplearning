<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>第 2 章 基础知识 | 深度学习文档集</title>
  <meta name="description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="第 2 章 基础知识 | 深度学习文档集" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  <meta name="github-repo" content="iotctech/deeplearning" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="第 2 章 基础知识 | 深度学习文档集" />
  
  <meta name="twitter:description" content="This is a minimal example of using the bookdown package to write a book. The output format for this example is bookdown::gitbook." />
  

<meta name="author" content="贝塔" />


<meta name="date" content="2020-03-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="literature.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Deep Learning Literature</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> 写在前面</a></li>
<li class="chapter" data-level="2" data-path="prepare.html"><a href="prepare.html"><i class="fa fa-check"></i><b>2</b> 基础知识</a>
<ul>
<li class="chapter" data-level="2.1" data-path="prepare.html"><a href="prepare.html#sec:exp"><i class="fa fa-check"></i><b>2.1</b> 指数族</a></li>
<li class="chapter" data-level="2.2" data-path="prepare.html"><a href="prepare.html#sec:lse"><i class="fa fa-check"></i><b>2.2</b> 最小二乘估计</a></li>
<li class="chapter" data-level="2.3" data-path="prepare.html"><a href="prepare.html#sec:def-mle"><i class="fa fa-check"></i><b>2.3</b> 极大似然估计</a></li>
<li class="chapter" data-level="2.4" data-path="prepare.html"><a href="prepare.html#sec:stationary-gaussian-process"><i class="fa fa-check"></i><b>2.4</b> 平稳高斯过程</a></li>
<li class="chapter" data-level="2.5" data-path="prepare.html"><a href="prepare.html#sec:bayes-prior"><i class="fa fa-check"></i><b>2.5</b> 先验和后验分布</a></li>
<li class="chapter" data-level="2.6" data-path="prepare.html"><a href="prepare.html#sec:bayes-estimates"><i class="fa fa-check"></i><b>2.6</b> 常用贝叶斯估计</a></li>
<li class="chapter" data-level="2.7" data-path="prepare.html"><a href="prepare.html#sec:foundations"><i class="fa fa-check"></i><b>2.7</b> 本章小结</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="literature.html"><a href="literature.html"><i class="fa fa-check"></i><b>3</b> Literature</a></li>
<li class="chapter" data-level="4" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>4</b> Methods</a></li>
<li class="chapter" data-level="5" data-path="applications.html"><a href="applications.html"><i class="fa fa-check"></i><b>5</b> Applications</a>
<ul>
<li class="chapter" data-level="5.1" data-path="applications.html"><a href="applications.html#example-one"><i class="fa fa-check"></i><b>5.1</b> Example one</a></li>
<li class="chapter" data-level="5.2" data-path="applications.html"><a href="applications.html#example-two"><i class="fa fa-check"></i><b>5.2</b> Example two</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="final-words.html"><a href="final-words.html"><i class="fa fa-check"></i><b>6</b> Final Words</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">本论文由 bookdown 强力驱动</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">深度学习文档集</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="prepare" class="section level1" number="2">
<h1><span class="header-section-number">第 2 章</span> 基础知识</h1>
<p>作为第 <a href="#models"><strong>??</strong></a> 章统计模型和第 <a href="#algorithms"><strong>??</strong></a> 章参数估计的知识准备，本章给出主要的知识点。第 <a href="prepare.html#sec:exp">2.1</a> 节首先介绍指数族的一般形式，包含各成分的定义，特别介绍正态分布、二项分布和泊松分布情形下均值函数、联系函数和方差函数等特征量。第 <a href="prepare.html#sec:lse">2.2</a> 节介绍线性模型下，设计矩阵保持正定时的最小二乘估计和加权最小二乘估计。第 <a href="prepare.html#sec:def-mle">2.3</a> 节介绍极大似然估计的定义，相合性，以及在一定条件下的渐近正态性。第 <a href="prepare.html#sec:stationary-gaussian-process">2.4</a> 节介绍平稳高斯过程的定义，均方连续性和可微性的定义，以及判断可微性的一个充要条件。第 <a href="prepare.html#sec:bayes-prior">2.5</a> 介绍先验、后验分布和 Jeffreys 无信息先验分布。</p>
<div id="sec:exp" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> 指数族</h2>
<p>一般地，随机变量 <span class="math inline">\(Y\)</span> 的分布服从指数族，即形如
<span class="math display" id="eq:common-exponential-family">\[\begin{equation}
f_{Y}(y;\theta,\phi) = \exp\big\{ \big(y\theta - b(\theta) \big)/a(\phi) + c(y,\phi) \big\}
\tag{2.1}
\end{equation}\]</span>
其中，<span class="math inline">\(a(\cdot),b(\cdot),c(\cdot)\)</span> 是某些特定的函数。如果 <span class="math inline">\(\phi\)</span> 已知，这是一个含有典则参数 <span class="math inline">\(\theta\)</span> 的指数族模型，如果 <span class="math inline">\(\phi\)</span> 未知，它可能是含有两个参数的指数族。对于正态分布
<span class="math display" id="eq:normal-distribution">\[\begin{equation}
\begin{aligned}
f_{Y}(y;\theta,\phi) &amp; = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\{-\frac{(y - \mu)^2}{2\sigma^2}  \}  \\
 &amp; = \exp\big \{ (y\mu - \mu^2/2)/\sigma^2 - \frac{1}{2}\big(y^2/\sigma^2 + \log(2\pi\sigma^2)\big) \big\}
\end{aligned} \tag{2.2}
\end{equation}\]</span>
通过与 <a href="prepare.html#eq:common-exponential-family">(2.1)</a> 式对比，可知 <span class="math inline">\(\theta = \mu\)</span>，<span class="math inline">\(\phi = \sigma^2\)</span>，并且有
<span class="math display">\[
a(\phi) = \phi, \quad b(\theta) = \theta^2/2, \quad c(y,\phi) = - \frac{1}{2}\{ y^2/\sigma^2 + \log(2\pi\sigma^2) \} 
\]</span>
记 <span class="math inline">\(l(\theta,\phi;y) = \log f_{Y}(y;\theta,\phi)\)</span> 为给定样本点 <span class="math inline">\(y\)</span> 的情况下，关于 <span class="math inline">\(\theta\)</span> 和 <span class="math inline">\(\phi\)</span> 的对数似然函数。样本 <span class="math inline">\(Y\)</span> 的均值和方差具有如下关系 <span class="citation">(McCullagh and Nelder <a href="#ref-McCullagh1989" role="doc-biblioref">1989</a>)</span>
<span class="math display" id="eq:mean-log-lik">\[\begin{equation}
\mathsf{E}\big( \frac{\partial l}{\partial \theta} \big) = 0
\tag{2.3}
\end{equation}\]</span>
和
<span class="math display" id="eq:variance-log-lik">\[\begin{equation}
\mathsf{E}\big( \frac{\partial^2 l}{\partial \theta^2} \big) + \mathsf{E}\big(\frac{\partial l}{\partial \theta}\big)^2  = 0
\tag{2.4}
\end{equation}\]</span>
从 <a href="prepare.html#eq:common-exponential-family">(2.1)</a> 式知
<span class="math display">\[ l(\theta,\phi;y) = {y\theta - b(\theta)}/a(\phi) + c(y,\phi) \]</span>
因此，
<span class="math display" id="eq:partial-log-lik">\[\begin{equation}
\begin{aligned}
\frac{\partial l}{\partial \theta} &amp; = {y - b&#39;(\theta)}/a(\phi)  \\
\frac{\partial^2 l}{\partial \theta^2}  &amp; = - b&#39;&#39;(\theta)/a(\phi)
\end{aligned} \tag{2.5}
\end{equation}\]</span>
从 <a href="prepare.html#eq:mean-log-lik">(2.3)</a> 式和 <a href="prepare.html#eq:partial-log-lik">(2.5)</a>，可以得出
<span class="math display">\[ 
0 = \mathsf{E}\big( \frac{\partial l}{\partial \theta} \big) = \big\{ \mu - b&#39;(\theta) \big\}/a(\phi)
\]</span>
所以
<span class="math display">\[ \mathsf{E}(Y) = \mu = b&#39;(\theta) \]</span>
根据 <a href="prepare.html#eq:variance-log-lik">(2.4)</a> 式和 <a href="prepare.html#eq:partial-log-lik">(2.5)</a> 式，可得
<span class="math display">\[ 0 = - \frac{b&#39;&#39;(\theta)}{a(\phi)} + \frac{\mathsf{Var}(Y)}{a^2(\phi)} \]</span>
所以
<span class="math display">\[ \mathsf{Var}(Y) = b&#39;&#39;(\theta)a(\phi) \]</span>
可见，<span class="math inline">\(Y\)</span> 的方差是两个函数的乘积，一个是 <span class="math inline">\(b&#39;&#39;(\theta)\)</span>， 它仅仅依赖典则参数，叫做方差函数，方差函数可以看作是 <span class="math inline">\(\mu\)</span> 的函数，记作 <span class="math inline">\(V(\mu)\)</span>。另一个是 <span class="math inline">\(a(\phi)\)</span>，它独立于 <span class="math inline">\(\theta\)</span>，仅仅依赖 <span class="math inline">\(\phi\)</span>，函数 <span class="math inline">\(a(\phi)\)</span> 通常形如
<span class="math display">\[ a(\phi) = \phi/w \]</span>
其中 <span class="math inline">\(\phi\)</span> 可由 <span class="math inline">\(\sigma^2\)</span> 表示，故而也叫做发散参数 （dispersion parameter），是一个与样本观察值相关的常数，<span class="math inline">\(w\)</span> 是已知的权重，随样本观察值变化。对正态分布模型而言，<span class="math inline">\(w\)</span> 的分量是 <span class="math inline">\(m\)</span> 个相互独立的样本观察值的均值，有 <span class="math inline">\(a(\phi) = \sigma^2/m\)</span>，所以，<span class="math inline">\(w = m\)</span>。</p>
<p>根据 <a href="prepare.html#eq:common-exponential-family">(2.1)</a>式，正态、泊松和二项分布的特征见表 <a href="prepare.html#tab:common-characteristics">2.1</a>，符号约定同 McCullagh 和 Nelder （1989年） 所著的《广义线性模型》。</p>
<table>
<caption><span id="tab:common-characteristics">表 2.1: </span> 指数族内常见的一元分布的共同特征及符号表示</caption>
<colgroup>
<col width="23%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">正态分布</th>
<th align="center">泊松分布</th>
<th align="center">二项分布</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">记号</td>
<td align="center"><span class="math inline">\(\mathcal{N}(\mu,\sigma^2)\)</span></td>
<td align="center"><span class="math inline">\(\mathrm{Poisson}(\mu)\)</span></td>
<td align="center"><span class="math inline">\(\mathrm{Binomial}(m,p)\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(y\)</span> 取值范围</td>
<td align="center"><span class="math inline">\((-\infty,\infty)\)</span></td>
<td align="center"><span class="math inline">\(0(1)\infty\)</span></td>
<td align="center"><span class="math inline">\(0(1)m\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(\phi\)</span></td>
<td align="center"><span class="math inline">\(\phi = \sigma^2\)</span></td>
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(1/m\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(b(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\theta^2/2\)</span></td>
<td align="center"><span class="math inline">\(\exp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(\log(1+e^{\theta})\)</span></td>
</tr>
<tr class="odd">
<td align="left"><span class="math inline">\(c(y;\theta)\)</span></td>
<td align="center"><span class="math inline">\(-\frac{1}{2}\big( \frac{y^2}{\phi} + \log(2\pi\phi) \big)\)</span></td>
<td align="center"><span class="math inline">\(-\log(y!)\)</span></td>
<td align="center"><span class="math inline">\(\log\binom{m}{my}\)</span></td>
</tr>
<tr class="even">
<td align="left"><span class="math inline">\(\mu(\theta) = \mathsf{E}(Y;\theta)\)</span></td>
<td align="center"><span class="math inline">\(\theta\)</span></td>
<td align="center"><span class="math inline">\(\exp(\theta)\)</span></td>
<td align="center"><span class="math inline">\(e^{\theta}/(1+e^{\theta})\)</span></td>
</tr>
<tr class="odd">
<td align="left">联系函数：<span class="math inline">\(\theta(\mu)\)</span></td>
<td align="center">identity</td>
<td align="center">log</td>
<td align="center">logit</td>
</tr>
<tr class="even">
<td align="left">方差函数：<span class="math inline">\(V(\mu)\)</span></td>
<td align="center">1</td>
<td align="center"><span class="math inline">\(\mu\)</span></td>
<td align="center"><span class="math inline">\(\mu(1-\mu)\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="sec:lse" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> 最小二乘估计</h2>
考虑如下线性模型的最小二乘估计
<span class="math display" id="eq:linear-models">\[\begin{equation}
\mathsf{E}\mathbf{Y} = \mathbf{X}\boldsymbol{\beta} \qquad \mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{I}_{n} \tag{2.6}
\end{equation}\]</span>
其中， <span class="math inline">\(\mathbf{Y}\)</span> 为 <span class="math inline">\(n \times 1\)</span> 维观测向量， <span class="math inline">\(\mathbf{X}\)</span> 为已知的 <span class="math inline">\(n \times p (p \leq n)\)</span> 维设计矩阵，<span class="math inline">\(\boldsymbol{\beta}\)</span> 为 <span class="math inline">\(p \times 1\)</span> 维未知参数，<span class="math inline">\(\sigma^2\)</span> 未知，<span class="math inline">\(\mathbf{I}_{n}\)</span> 为 <span class="math inline">\(n\)</span> 阶单位阵。

<div class="definition">
<span id="def:least-squares-estimate" class="definition"><strong>定义 2.1  (最小二乘估计)  </strong></span>在模型 <a href="prepare.html#eq:linear-models">(2.6)</a> 中，如果
<span class="math display" id="eq:least-squares">\[\begin{equation}
(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}})^{\top}(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}) = \min_{\beta}(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta})^{\top}(\mathbf{Y} - \mathbf{X}\boldsymbol{\beta}) \tag{2.7}
\end{equation}\]</span>
则称 <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> 为 <span class="math inline">\(\boldsymbol{\beta}\)</span> 的最小二乘估计(简称 LSE)<span class="citation">(王松桂 et al. <a href="#ref-wang2004" role="doc-biblioref">2004</a>)</span>。
</div>

<div class="theorem">
<span id="thm:unbiased" class="theorem"><strong>定理 2.1  (最小二乘估计)  </strong></span>若模型 <a href="prepare.html#eq:linear-models">(2.6)</a> 中的 <span class="math inline">\(\mathbf{X}\)</span> 是列满秩的矩阵，则 <span class="math inline">\(\boldsymbol{\beta}\)</span> 的最小二乘估计为
<span class="math display">\[
\hat{\boldsymbol{\beta}}_{LS} = ( \mathbf{X}^{\top}\mathbf{X} )^{-1}\mathbf{X}^{\top} \mathbf{Y}, \quad  \mathsf{Var}(\hat{\boldsymbol{\beta}}_{LS}) = \sigma^2 (\mathbf{X}^{\top}\mathbf{X})^{-1}  
\]</span>
<span class="math inline">\(\sigma^2\)</span> 的最小二乘估计为
<span class="math display">\[
\hat{\sigma^2}_{LS} = (\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}_{LS})^{\top}(\mathbf{Y} - \mathbf{X}\hat{\boldsymbol{\beta}}_{LS})/(n - p)
\]</span>
若将模型 <a href="prepare.html#eq:linear-models">(2.6)</a> 的条件 <span class="math inline">\(\mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{I}_{n}\)</span> 改为 <span class="math inline">\(\mathsf{Var}(\mathbf{Y}) = \sigma^2 \mathbf{G}\)</span>， <span class="math inline">\(\mathbf{G}(&gt;0)\)</span> 为已知正定阵，则<span class="math inline">\(\boldsymbol{\beta}\)</span> 的最小二乘估计为
<span class="math display">\[
\tilde{\boldsymbol{\beta}}_{LS} = ( \mathbf{X}^{\top} \mathbf{G}^{-1} \mathbf{X})^{-1} \mathbf{X}^{\top} \mathbf{G}^{-1} \mathbf{Y} 
\]</span>
称 <span class="math inline">\(\tilde{\boldsymbol{\beta}}_{LS}\)</span> 为广义最小二乘估计，特别地，当 <span class="math inline">\(\mathbf{G} = \mathrm{diag}(\sigma^2_{1},\ldots,\sigma^2_{n})\)</span>，<span class="math inline">\(\sigma^2_{i},i = 1,\ldots,n\)</span> 已知时，称 <span class="math inline">\(\tilde{\boldsymbol{\beta}}_{LS}\)</span> 为加权最小二乘估计<span class="citation">(王松桂 et al. <a href="#ref-wang2004" role="doc-biblioref">2004</a>)</span>。
</div>
</div>
<div id="sec:def-mle" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> 极大似然估计</h2>

<div class="definition">
<span id="def:maximum-likelihood-estimate" class="definition"><strong>定义 2.2  (极大似然估计)  </strong></span>设 <span class="math inline">\(p(\mathbf{x};\boldsymbol{\theta}),\boldsymbol{\theta} \in \boldsymbol{\Theta}\)</span> 是 <span class="math inline">\((\mathbb{R}^n,\mathscr{P}_{\mathbb{R}^n})\)</span> 上的一族联合密度函数，对给定的 <span class="math inline">\(\mathbf{x}\)</span>，称
<span class="math display">\[ L(\boldsymbol{\theta};\mathbf{x}) = kp(\mathbf{x};\boldsymbol{\theta}) \]</span>
为 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的似然函数，其中 <span class="math inline">\(k &gt; 0\)</span> 是不依赖于 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的量，常取 <span class="math inline">\(k=1\)</span>。进一步，若存在 <span class="math inline">\((\mathbb{R}^n,\mathscr{P}_{\mathbb{R}^n})\)</span> 到 <span class="math inline">\((\boldsymbol{\Theta},\mathscr{P}_{\boldsymbol{\Theta}})\)</span> 的统计量 <span class="math inline">\(\hat{\boldsymbol{\theta}}(\mathbf{x})\)</span> 使
<span class="math display">\[ L(\hat{\boldsymbol{\theta}}(\mathbf{x});\mathbf{x}) = \sup_{\boldsymbol{\theta}} L(\boldsymbol{\theta};\mathbf{x}) \]</span>
则 <span class="math inline">\(\hat{\boldsymbol{\theta}}(\mathbf{x})\)</span> 称为 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的一个极大似然估计（简称 MLE）<span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。
</div>
<p>概率密度函数很多可以写成具有指数函数的形式，如指数族，采用似然函数的对数通常更为简便。称
<span class="math display">\[ l(\boldsymbol{\theta},\mathbf{x}) = \ln L(\boldsymbol{\theta},\mathbf{x}) \]</span>
为 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的对数似然函数。对数变换是严格单调的，所以 <span class="math inline">\(l(\boldsymbol{\theta},\mathbf{x})\)</span> 与 <span class="math inline">\(L(\boldsymbol{\theta},\mathbf{x})\)</span> 的极大值是等价的。当 MLE 存在时，寻找 MLE 的常用方法是求导数。如果 <span class="math inline">\(\hat{\boldsymbol{\theta}}(\mathbf{x})\)</span> 是 <span class="math inline">\(\boldsymbol{\Theta}\)</span> 的内点，则 <span class="math inline">\(\hat{\boldsymbol{\theta}}(\mathbf{x})\)</span> 是下列似然方程组
<span class="math display" id="eq:likelihood-equations">\[\begin{equation}
\partial l(\boldsymbol{\theta},\mathbf{x})/ \partial \boldsymbol{\theta}_{i} = 0, \quad i = 1,\ldots, m \tag{2.8}
\end{equation}\]</span>
的解。<span class="math inline">\(p(\mathbf{x};\boldsymbol{\theta})\)</span> 属于指数族时，似然方程组 <a href="prepare.html#eq:likelihood-equations">(2.8)</a> 的解唯一<span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。</p>

<div class="theorem">
<p><span id="thm:consistency" class="theorem"><strong>定理 2.2  (相合性)  </strong></span>设 <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> 是来自概率密度函数 <span class="math inline">\(p(\mathbf{x};\boldsymbol{\theta})\)</span> 的一个样本，叙述简单起见，考虑单参数情形，参数空间 <span class="math inline">\(\boldsymbol{\Theta}\)</span> 是一个开区间，<span class="math inline">\(l(\boldsymbol{\theta};\mathbf{x}) = \sum_{i=1}^{n}\ln p(x_{i};\boldsymbol{\theta})\)</span>。</p>
若 <span class="math inline">\(\ln (p;\boldsymbol{\theta})\)</span> 在 <span class="math inline">\(\boldsymbol{\Theta}\)</span> 上可微，且 <span class="math inline">\(p(\mathbf{x};\boldsymbol{\theta})\)</span> 是可识别的（即 <span class="math inline">\(\forall \boldsymbol{\theta}_1 \neq \boldsymbol{\theta}_2, \{\mathbf{x}: p(\mathbf{x};\boldsymbol{\theta}_1) \neq p(\mathbf{x}; \boldsymbol{\theta}_2)\}\)</span> 不是零测集），则似然方程 <a href="prepare.html#eq:likelihood-equations">(2.8)</a> 在 <span class="math inline">\(n \to \infty\)</span> 时，以概率 <span class="math inline">\(1\)</span> 有解，且此解关于 <span class="math inline">\(\boldsymbol{\theta}\)</span> 是相合的<span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。
</div>

<div class="theorem">
<p><span id="thm:asymptotic-normality" class="theorem"><strong>定理 2.3  (渐近正态性)  </strong></span>假设 <span class="math inline">\(\boldsymbol{\Theta}\)</span> 为开区间，概率密度函数 <span class="math inline">\(p(\mathbf{x};\boldsymbol{\theta}), \boldsymbol{\theta} \in \boldsymbol{\Theta}\)</span> 满足：</p>
<ol style="list-style-type: decimal">
<li>在参数真值 <span class="math inline">\(\boldsymbol{\theta}_{0}\)</span> 的邻域内，<span class="math inline">\(\partial \ln p/\partial \boldsymbol{\theta}, \partial^2 \ln p/\partial \boldsymbol{\theta}^2, \partial^3 \ln p/\partial \boldsymbol{\theta}^3\)</span> 对所有的 <span class="math inline">\(\mathbf{x}\)</span> 都存在；</li>
<li>在参数真值 <span class="math inline">\(\boldsymbol{\theta}_{0}\)</span> 的邻域内，<span class="math inline">\(| \partial^3 \ln p/\partial \boldsymbol{\theta}^3 | \leq H(\mathbf{x})\)</span>，且 <span class="math inline">\(\mathsf{E}H(\mathbf{x}) &lt; \infty\)</span>；</li>
<li>在参数真值 <span class="math inline">\(\boldsymbol{\theta}_{0}\)</span> 处，<span class="math inline">\(\mathsf{E}_{\boldsymbol{\theta}_{0}} \big[ \frac{ p&#39;(\mathbf{x},\boldsymbol{\theta}_{0}) }{ p(\mathbf{x},\boldsymbol{\theta}_{0}) } \big] = 0,\mathsf{E}_{\boldsymbol{\theta}_{0}} \big[ \frac{ p&#39;&#39;(\mathbf{x},\boldsymbol{\theta}_{0}) }{ p(\mathbf{x},\boldsymbol{\theta}_{0}) } \big] = 0,I(\boldsymbol{\theta}_{0}) = \mathsf{E}_{\boldsymbol{\theta}_{0}} \big[ \frac{ p&#39;(\mathbf{x},\boldsymbol{\theta}_{0}) }{ p(\mathbf{x},\boldsymbol{\theta}_{0}) } \big]^{2} &gt; 0\)</span>。</li>
</ol>
其中，撇号表示对 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的微分。记 <span class="math inline">\(\hat{\boldsymbol{\theta}}_{n}\)</span> 为 <span class="math inline">\(n \to \infty\)</span> 时，似然方程组的相合解，则<span class="math inline">\(\sqrt{n}(\hat{\boldsymbol{\theta}}_{n} - \boldsymbol{\theta}_{0}) \longrightarrow \mathcal{N}(\mathbf{0},I^{-1}(\boldsymbol{\theta}))\)</span><span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。
</div>
</div>
<div id="sec:stationary-gaussian-process" class="section level2" number="2.4">
<h2><span class="header-section-number">2.4</span> 平稳高斯过程</h2>
<p>一般地，空间高斯过程 <span class="math inline">\(\mathcal{S} = \{S(x),x\in\mathbb{R}^2\}\)</span> 必须满足条件：任意给定一组空间位置 <span class="math inline">\(x_1,x_2,\ldots,x_n, \forall x_{i} \in \mathbb{R}^2\)</span>， 每个位置上对应的随机变量 <span class="math inline">\(S(x_i), i = 1,2,\ldots,n\)</span> 的联合分布 <span class="math inline">\(\mathcal{S} = \{S(x_1), S(x_2),\ldots,S(x_n)\}\)</span> 是多元高斯分布，其由均值 <span class="math inline">\(\mu(x) = \mathsf{E}[S(x)]\)</span> 和协方差 <span class="math inline">\(G_{ij} = \gamma(x_i,x_j) = \mathsf{Cov}\{S(x_i),S(x_j)\}\)</span> 完全确定，即 <span class="math inline">\(\mathcal{S} \sim \mathcal{N}(\mu_{S},G)\)</span>。</p>
<p>平稳空间高斯过程需要空间高斯过程满足平稳性条件：其一， <span class="math inline">\(\mu(x) = \mu, \forall x \in \mathbb{R}^2\)</span>， 其二，自协方差函数 <span class="math inline">\(\gamma(x_i,x_j) = \gamma(u),u=\|x_{i} - x_{j}\|\)</span>。 可见均值 <span class="math inline">\(\mu\)</span> 是一个常数， 而自协方差函数 <span class="math inline">\(\gamma(x_i,x_j)\)</span> 只与空间距离有关。</p>
<p>平稳高斯过程 <span class="math inline">\(\mathcal{S}\)</span> 的方差是一个常数，即 <span class="math inline">\(\sigma^2 = \gamma(0)\)</span>， 然后可以定义自相关函数 <span class="math inline">\(\rho(u) = \gamma(u)/\sigma^2\)</span>， 并且 <span class="math inline">\(\rho(u)\)</span> 是关于空间距离<span class="math inline">\(u\)</span>对称的，即 <span class="math inline">\(\rho(u) = \rho(-u)\)</span>。 因为对 <span class="math inline">\(\forall u, \mathsf{Corr}\{S(x),S(x-u)\} = \mathsf{Corr}\{S(x-u), S(x)\} = \mathsf{Corr}\{S(x),S(x+u)\}\)</span>， 这里的第二个等式是根据平稳性得来的， 由协方差的定义不难验证。 如果不特别说明， 平稳就指上述协方差意义下的平稳， 因为这种平稳性条件广泛应用于空间数据的统计建模。不失一般性，介绍一维空间下随机过程 <span class="math inline">\(S(x)\)</span> 的均方连续性和可微性定义。</p>

<div class="definition">
<span id="def:continuous-differentiable" class="definition"><strong>定义 2.3  (连续性和可微性)  </strong></span>随机过程 <span class="math inline">\(S(x)\)</span> 满足
<span class="math display">\[ \lim_{h \to 0} \mathsf{E}\big[ \{S(x + h) - S(x)\}^{2} \big] = 0 \]</span>
则称 <span class="math inline">\(S(x)\)</span> 是均方连续（mean-square continuous）的。随机过程 <span class="math inline">\(S(x)\)</span> 满足
<span class="math display">\[ \lim_{h \to 0} \mathsf{E} \big[ \{ \frac{S(x+h) - S(x)}{h} - S&#39;(x) \}^2 \big] = 0 \]</span>
则称 <span class="math inline">\(S(x)\)</span> 是均方可微（mean-square differentiable）的，并且 <span class="math inline">\(S&#39;(x)\)</span> 就是均方意义下的一阶导数。如果 <span class="math inline">\(S&#39;(x)\)</span> 是均方可微的，则 <span class="math inline">\(S(x)\)</span> 是二次均方可微的，随机过程 <span class="math inline">\(S(x)\)</span> 的高阶均方可微性可类似定义<span class="citation">(Diggle and Ribeiro Jr., <a href="#ref-Diggle2007" role="doc-biblioref">n.d.</a>)</span>。Bartlett （1955 年） <span class="citation">(Bartlett <a href="#ref-Bartlett1955" role="doc-biblioref">1955</a>)</span> 得到如下重要结论
</div>

<div class="theorem">
<span id="thm:stationary-mean-square-properties" class="theorem"><strong>定理 2.4  (平稳随机过程的可微性)  </strong></span>自相关函数为 <span class="math inline">\(\rho(u)\)</span> 的平稳随机过程是 <span class="math inline">\(k\)</span> 次均方可微的，当且仅当 <span class="math inline">\(\rho(u)\)</span> 在 <span class="math inline">\(u = 0\)</span> 处是 <span class="math inline">\(2k\)</span> 次可微的。
</div>
</div>
<div id="sec:bayes-prior" class="section level2" number="2.5">
<h2><span class="header-section-number">2.5</span> 先验和后验分布</h2>
<p>贝叶斯推断中，常涉及模型参数的先验、后验分布，以及一种特殊的无信息先验分布 — Jeffreys 先验，下面分别给出它们的概念定义<span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。</p>

<div class="definition">
<span id="def:prior-distribution" class="definition"><strong>定义 2.4  (先验分布)  </strong></span>参数空间 <span class="math inline">\(\Theta\)</span> 上的任一概率分布都称作先验分布 （prior distribution）<span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。
</div>

<div class="definition">
<span id="def:posterior-distribution" class="definition"><strong>定义 2.5  (后验分布)  </strong></span>在获得样本 <span class="math inline">\(\mathbf{Y}\)</span> 后，模型参数 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的后验分布 （posterior distribution） 就是在给定样本 <span class="math inline">\(\mathbf{Y}\)</span> 的条件下 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的分布<span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。
</div>

<div class="definition">
<span id="def:Jeffreys-prior-distribution" class="definition"><strong>定义 2.6  (Jeffreys 先验分布)  </strong></span>设 <span class="math inline">\(\mathbf{x} = (x_1,\ldots,x_n)\)</span> 是来自密度函数 <span class="math inline">\(p(x|\boldsymbol{\theta})\)</span> 的一个样本，其中 <span class="math inline">\(\boldsymbol{\theta} = (\theta_1,\ldots,\theta_p)\)</span> 是 <span class="math inline">\(p\)</span> 维参数向量。在对 <span class="math inline">\(\boldsymbol{\theta}\)</span> 无任何先验信息可用时， Jeffreys （1961年）利用变换群和 Harr 测度导出 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的无信息先验分布可用 Fisher 信息阵的行列式的平方根表示。这种无信息先验分布常称为 Jeffreys 先验分布。其求取步骤如下：
</div>
<ol style="list-style-type: decimal">
<li>写出样本的对数似然函数 <span class="math inline">\(l(\boldsymbol{\theta}|x) = \sum_{i=1}^{n}\ln p(x_i | \boldsymbol{\theta})\)</span>；</li>
<li>算出参数 <span class="math inline">\(\boldsymbol{\theta}\)</span> 的 Fisher 信息阵 <span class="math display">\[\mathbf{I}(\boldsymbol{\theta}) = \mathsf{E}_{x|\theta} \big( - \frac{\partial^2 l}{\partial \theta_i \partial \theta_j} \big)_{i,j=1,\ldots,p}\]</span> 在单参数场合， <span class="math inline">\(\mathbf{I}(\theta) = \mathsf{E}_{x|\theta} \big( - \frac{\partial^2 l}{\partial \theta^2} \big)\)</span>；</li>
<li><span class="math inline">\(\boldsymbol{\theta}\)</span> 的无信息先验密度函数为 <span class="math inline">\(\pi(\boldsymbol{\theta}) = [\det \mathbf{I}(\boldsymbol{\theta}) ]^{1/2}\)</span>，在单参数场合， <span class="math inline">\(\pi(\boldsymbol{\theta}) = [\mathbf{I}(\theta) ]^{1/2}\)</span><span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。</li>
</ol>
</div>
<div id="sec:bayes-estimates" class="section level2" number="2.6">
<h2><span class="header-section-number">2.6</span> 常用贝叶斯估计</h2>

<div class="theorem">
<span id="thm:bayes-estimate-square" class="theorem"><strong>定理 2.5  (平方损失)  </strong></span>在给定先验分布 <span class="math inline">\(\pi(\boldsymbol{\theta})\)</span> 和平方损失 <span class="math inline">\(L(\boldsymbol{\theta},\boldsymbol{\delta}) = (\boldsymbol{\delta} - \boldsymbol{\theta})^2\)</span> 下，<span class="math inline">\(\boldsymbol{\theta}\)</span> 的贝叶斯估计 <span class="math inline">\(\boldsymbol{\delta}^{\pi}(x)\)</span> 为后验分布 <span class="math inline">\(\pi(\boldsymbol{\theta}|x)\)</span> 的均值，即 <span class="math inline">\(\boldsymbol{\delta}^{\pi}(x) = \mathsf{E}(\boldsymbol{\theta}|x)\)</span><span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。
</div>

<div class="theorem">
<p><span id="thm:bayes-estimate-01" class="theorem"><strong>定理 2.6  (0 - 1 损失)  </strong></span>在给定先验分布 <span class="math inline">\(\pi(\boldsymbol{\theta})\)</span> 和 <span class="math inline">\(0\)</span> - <span class="math inline">\(1\)</span> 损失函数</p>
<p><span class="math display">\[\begin{equation*}
L(\boldsymbol{\theta},\boldsymbol{\delta}) = 
\begin{cases}
1, &amp; | \boldsymbol{\delta} - \boldsymbol{\theta}| \leq \epsilon \\
0, &amp; | \boldsymbol{\delta} - \boldsymbol{\theta}| &gt; \epsilon
\end{cases}
\end{equation*}\]</span></p>
当 <span class="math inline">\(\epsilon\)</span> 较小时，<span class="math inline">\(\boldsymbol{\theta}\)</span> 的贝叶斯估计<span class="math inline">\(\boldsymbol{\delta}^{\pi}(x)\)</span>为后验分布 <span class="math inline">\(\pi(\boldsymbol{\theta}|x)\)</span> 的众数<span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。
</div>

<div class="theorem">
<span id="thm:bayes-estimate-abs" class="theorem"><strong>定理 2.7  (绝对值损失)  </strong></span>在给定先验分布 <span class="math inline">\(\pi(\boldsymbol{\theta})\)</span> 和绝对损失函数 <span class="math inline">\(L(\boldsymbol{\theta},\boldsymbol{\delta}) = |\boldsymbol{\delta} - \boldsymbol{\theta}|\)</span> 下，<span class="math inline">\(\boldsymbol{\theta}\)</span> 的贝叶斯估计 <span class="math inline">\(\boldsymbol{\delta}^{\pi}(x)\)</span> 为后验分布 <span class="math inline">\(\pi(\boldsymbol{\theta}|x)\)</span> 的中位数<span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。
</div>
<p>评价贝叶斯估计 <span class="math inline">\(\boldsymbol{\delta}^{\pi}(x)\)</span> 的精度常用后验均方误差
<span class="math display">\[\mathsf{MSE}(\boldsymbol{\delta}^{\pi}|x) = \mathsf{E}_{\boldsymbol{\theta}|x}(\boldsymbol{\delta}^{\pi} - \boldsymbol{\theta})^2\]</span>
表示，或用其平方根<span class="math inline">\([\mathsf{MSE}(\boldsymbol{\delta}^{\pi}|x)]^{1/2}\)</span> （称为标准误）表示。容易算得
<span class="math display">\[\mathsf{MSE}(\boldsymbol{\delta}^{\pi}|x) = \mathsf{Var}(\boldsymbol{\delta}^{\pi}|x) + [\boldsymbol{\delta}^{\pi}(x) - \mathsf{E}(\boldsymbol{\theta}|x)]^2\]</span>
可见，当贝叶斯估计<span class="math inline">\(\boldsymbol{\delta}^{\pi}(x)\)</span>为后验均值时，贝叶斯估计的精度就用<span class="math inline">\(\boldsymbol{\delta}^{\pi}\)</span>的后验方差<span class="math inline">\(\mathsf{Var}(\boldsymbol{\delta}^{\pi}|x)\)</span> 表示，或用后验标准差 <span class="math inline">\([\mathsf{Var}(\boldsymbol{\delta}^{\pi}|x)]^{1/2}\)</span> 表示 <span class="citation">(茆诗松, 王静龙, and 濮晓龙 <a href="#ref-mao2006" role="doc-biblioref">2006</a>)</span>。</p>
</div>
<div id="sec:foundations" class="section level2" number="2.7">
<h2><span class="header-section-number">2.7</span> 本章小结</h2>
<p>本章第<a href="prepare.html#sec:exp">2.1</a>节介绍了指数族的一般形式，指出基于样本点的对数似然函数和样本均值、样本方差的关系，以表格的形式列出了正态、泊松和二项分布的各个特征，为第<a href="#models"><strong>??</strong></a>章统计模型和第<a href="#algorithms"><strong>??</strong></a>章参数估计作铺垫。接着，第<a href="prepare.html#sec:lse">2.2</a>节和第<a href="prepare.html#sec:def-mle">2.3</a>节分别介绍了最小二乘估计和极大似然估计的定义、性质，给出了线性模型的最小二乘估计，极大似然估计的相合性和渐进正态性。第<a href="prepare.html#sec:stationary-gaussian-process">2.4</a>节介绍了平稳高斯过程，给出了其均方连续性、可微性定义以及一个均方可微的判断定理，平稳高斯过程作为空间随机效应的实现，多次出现在后续章节中。第<a href="prepare.html#sec:bayes-prior">2.5</a>节至第<a href="prepare.html#sec:bayes-estimates">2.6</a>节分别是与贝叶斯相关的概念定义。</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Bartlett1955">
<p>Bartlett, M. S. 1955. <em>An Introduction to Stochastic Process with Special Reference to Methods and Applications</em>. First. Cambridge: Cambridge University Press.</p>
</div>
<div id="ref-Diggle2007">
<p>Diggle, Peter J., and Paulo J. Ribeiro Jr. n.d. <em>Model-Based Geostatistics</em>. New York, NY: Springer-Verlag.</p>
</div>
<div id="ref-McCullagh1989">
<p>McCullagh, Peter, and John Nelder. 1989. <em>Generalized Linear Models</em>. Second. London: Chapman; Hall/CRC.</p>
</div>
<div id="ref-wang2004">
<p>王松桂, 史建红, 尹素菊, and 吴密霞. 2004. <em>线性模型引论</em>. 北京: 科学出版社.</p>
</div>
<div id="ref-mao2006">
<p>茆诗松, 王静龙, and 濮晓龙. 2006. <em>高等数理统计</em>. 第二版. 北京: 高等教育出版社.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="literature.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/iotctech/deeplearning/edit/master/01-foundations.Rmd",
"text": "编辑"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Deep-Learning-Book.pdf", "Deep-Learning-Book.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
